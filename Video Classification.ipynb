{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bb106f-5372-45fc-a4b7-4372068b80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import requests\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5091cf12-4b3f-4f57-9da6-bb8adda9a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35393b3-1854-43af-bfa8-04b9e0bf3a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
      "                                                                 \n",
      " pooling_layer (GlobalAverag  (None, 1280)             0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 3843      \n",
      "                                                                 \n",
      " softmax_float32 (Activation  (None, 3)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,053,414\n",
      "Trainable params: 3,843\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./GL_classification_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893005d1-73a2-49e9-8965-5cf5355b8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothOutImgEdges(img):\n",
    "    canny_img = cv2.Canny(img, 50, 140)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.dilate(canny_img , kernel, iterations = 4)\n",
    "    return kernel, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954fc985-6428-462e-bb56-7195ed75cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBiggestContour(img):\n",
    "    kernel, mask = smoothOutImgEdges(img)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    biggest_contour = 0\n",
    "    biggest_area = 0\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > biggest_area:\n",
    "            biggest_area = area\n",
    "            biggest_contour = np.array(contour).reshape((-1,1,2))\n",
    "    return kernel, mask, biggest_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f70791-0fa8-4b3e-b790-148085954325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSmallContours(crop_mask):\n",
    "    inverted_mask = cv2.bitwise_not(crop_mask)\n",
    "    contours, _ = cv2.findContours(inverted_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    small_contours = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < 10000:\n",
    "            small_contours.append(contour)\n",
    "    return small_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d19ad8-0919-4690-8ac0-cd5ea2c9df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBackgroundNoise(crop_mask, kernel):\n",
    "    crop_zero_mask = cv2.erode(crop_mask, kernel, iterations = 1)\n",
    "    crop_zero_mask = cv2.dilate(crop_zero_mask, kernel, iterations = 1)\n",
    "    crop_zero_mask = cv2.medianBlur(crop_zero_mask, 5)\n",
    "    return crop_zero_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d02fff-6d43-422d-852f-8941395f4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_over_image(img):\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    kernel, mask, biggest_contour = findBiggestContour(gray_img)\n",
    "    crop_zero_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(crop_zero_mask, [biggest_contour], -1, (255), -1)\n",
    "    \n",
    "    small_contours = findSmallContours(crop_zero_mask)\n",
    "    cv2.drawContours(crop_zero_mask, small_contours, -1, (255), -1)\n",
    "    crop_zero_mask = removeBackgroundNoise(crop_zero_mask, kernel)\n",
    "    crop = np.zeros_like(img)\n",
    "    crop[crop_zero_mask == 255] = img[crop_zero_mask == 255]\n",
    "    \n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ae6356-450f-4098-9baf-81cb9346b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['Compostable', 'Landfill', 'Recyclables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e9055c-196c-4097-ad86-100debab0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_predict_image(images, img_shape = 224):\n",
    "    \n",
    "    img = tf.convert_to_tensor(images)\n",
    "    img = tf.image.resize(img, [img_shape, img_shape])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30f0ee1-4f92-470a-b006-80df590f0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://192.168.184.197:8081/shot.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34d7809-392c-422b-a00b-c637cb297905",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\drawing.cpp:2509: error: (-215:Assertion failed) npoints > 0 in function 'cv::drawContours'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-548c10ee3e10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Normal\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcrop_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasked_over_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mcrop_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c3b5720917cb>\u001b[0m in \u001b[0;36mmasked_over_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiggest_contour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindBiggestContour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcrop_zero_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_zero_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbiggest_contour\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msmall_contours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindSmallContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_zero_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\drawing.cpp:2509: error: (-215:Assertion failed) npoints > 0 in function 'cv::drawContours'\n"
     ]
    }
   ],
   "source": [
    "while (True):\n",
    "    \n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    frame = cv2.imdecode(img_arr, -1)\n",
    "    frame = imutils.resize(frame, width=1000, height=1800)\n",
    "    \n",
    "    cv2.imshow(\"Normal\", frame)\n",
    "        \n",
    "    crop_frame = masked_over_image(frame)\n",
    "    crop_frame = cv2.cvtColor(crop_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    img = convert_and_predict_image(crop_frame) \n",
    "    pred_prob = model.predict(tf.expand_dims(img, axis=0)) #create a dimension 0 which is the batch size\n",
    "    pred_class = CLASSES[pred_prob.argmax()] \n",
    "        \n",
    "    crop_frame = cv2.putText(img = crop_frame, text = f\"Predicted: {pred_class}\", org = (20,30), \n",
    "                            fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            color = (255,0,0), fontScale = 1, thickness = 2, lineType = cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow(\"Prediction\", crop_frame)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95546878-67ad-4228-aa25-ddeaa771926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac501c6c-d058-4b02-a051-92f475418a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
